{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e97706-8608-4b1e-926f-fed953114ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "#Read substructures and datasets\n",
    "datasets = pd.read_excel('ML-improve.xlsx') #Not provided\n",
    "Dipyrone = datasets[datasets['Types of contaminants'] == 'Q']\n",
    "substructure = pd.read_csv('New Match1.txt',header = None)\n",
    "concatenated = pd.concat([Dipyrone.iloc[:, 7:27]], axis=1)\n",
    "arr3 = concatenated.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123d8a8-a464-40f5-a1a2-90d5d343e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Match all substructures of SMILES (and record the quantity)\n",
    "arr1 =[[0 for x in range(len(substructure))] for y in range(len(datasets))]\n",
    "smis =datasets.SMILES\n",
    "i = 0\n",
    "j = 0\n",
    "for smi in smis:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    for sub in substructure[0].values :\n",
    "        subMol = Chem.MolFromSmarts(sub)\n",
    "        matches = mol.GetSubstructMatches(subMol)\n",
    "        if len(matches):\n",
    "            arr1[i][j] = len(matches)\n",
    "            if sub =='c': \n",
    "                arr1[i][j] = arr1[i][j]/6\n",
    "        j = j+1\n",
    "    i= i+1\n",
    "    j=0\n",
    "\n",
    "arr = np.hstack((arr1, arr3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fbded-8565-4e55-b19e-3189cc8b3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Containing phenyl group\n",
    "row_numbers = []\n",
    "\n",
    "for index, row in enumerate(arr1):\n",
    "    if row[1] != 0:\n",
    "        row_numbers.append(index) \n",
    "selected_rows = datasets.loc[row_numbers]\n",
    "datasets = selected_rows \n",
    "\n",
    "arr1 =[[0 for x in range(len(substructure))] for y in range(len(datasets))]\n",
    "smis =datasets.SMILES\n",
    "i = 0\n",
    "j = 0\n",
    "for smi in smis:\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    for sub in substructure[0].values :\n",
    "        subMol = Chem.MolFromSmarts(sub)\n",
    "        matches = mol.GetSubstructMatches(subMol)\n",
    "        if len(matches):\n",
    "            arr1[i][j] = len(matches)\n",
    "            if sub =='c':\n",
    "                arr1[i][j] = arr1[i][j]/6\n",
    "        j = j+1\n",
    "    i= i+1\n",
    "    j=0\n",
    "\n",
    "arr3 = arr[row_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b063219-c456-4b70-a3e5-d9327e882c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = arr3\n",
    "y = Dipyrone.iloc[:, 27]\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "#Divide the training set and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)#37\n",
    "\n",
    "#Initialize the model\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "#Set hyperparameter candidate values\n",
    "param_grid = {\n",
    "    'colsample_bytree': [0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n",
    "    'learning_rate': [0.1, 0.01],\n",
    "    'max_depth': [3,4, 5,6,7,8,9,10],\n",
    "    'alpha': [10, 20, 30,40,50,60,70],\n",
    "    'n_estimators': [10,20,30,40 ,50,60,70,80,90,100]\n",
    "}\n",
    "\n",
    "#Create GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, scoring='r2', cv=5,n_jobs = -1)\n",
    "\n",
    "#Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#Output the optimal hyperparameter combination\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "#Use the model with optimal parameters for prediction\n",
    "best_model = grid_search.best_estimator_\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "print('training R2:', metrics.r2_score(y_train,y_train_pred))\n",
    "print('testing R2:', metrics.r2_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eeeedd-511f-4292-b678-429575545314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the optimal random_state\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "#Parameter candidate values - obtained from the above training, the following is a randomly given set of parameters\n",
    "param_grid = {\n",
    "    'colsample_bytree': [0.6],\n",
    "    'learning_rate': [0.1],\n",
    "    'max_depth': [7],\n",
    "    'alpha': [10],\n",
    "    'n_estimators': [100]\n",
    "}                                                                            \n",
    "\n",
    "#Initialize variables to store the best model and the highest R2 score\n",
    "best_r2 = -np.inf\n",
    "best_model = None\n",
    "best_random_state = None\n",
    "\n",
    "\n",
    "for random_state in range(160):\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "   \n",
    "    model = xgb.XGBRegressor()\n",
    "    \n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='r2', cv=5, n_jobs=-1)\n",
    "    \n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_test_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    test_r2 = metrics.r2_score(y_test, y_test_pred)\n",
    "    \n",
    "    #If the R2 score of the current model is higher than the previous best score, update the optimal model and score\n",
    "    if test_r2 > 0.8:\n",
    "        best_r2 = test_r2\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_random_state = random_state\n",
    "        y_train_pred = best_model.predict(X_train)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "        print('Best random_state:', best_random_state)\n",
    "        print('training R2:', metrics.r2_score(y_train, y_train_pred))\n",
    "        print('test R2:', metrics.r2_score(y_test, y_test_pred))\n",
    "\n",
    "\n",
    "y_train_pred = best_model.predict(X_train)\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# 输出训练和测试 R2 分数\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print('Best random_state:', best_random_state)\n",
    "print('training R2:', metrics.r2_score(y_train, y_train_pred))\n",
    "print('testing R2:', metrics.r2_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3625261a-2163-4c48-9958-e1d3adc2f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "#Initialize SHAP interpreter using the model with optimal parameters\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "\n",
    "#Calculate SHAP value\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "\n",
    "#Retrieve the name of each row in the substructure and convert it into a list\n",
    "substructure_names = substructure[0].tolist()\n",
    "feature_names = []\n",
    "\n",
    "#Add the name of the original feature\n",
    "for col_name in concatenated.columns:\n",
    "    feature_names.append(col_name)\n",
    "\n",
    "# Add the infrastructure name, and original feature name to feature_name\n",
    "feature_names = substructure_names  + feature_names\n",
    "\n",
    "shap.summary_plot(shap_values, X_train, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ef549-085b-445a-87fb-78dc5bc809b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Molecular fingerprint analysis\n",
    "sub = shap_values[:,:12]\n",
    "shap.summary_plot(sub, X_train[:, :12],feature_names=substructure_names) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
